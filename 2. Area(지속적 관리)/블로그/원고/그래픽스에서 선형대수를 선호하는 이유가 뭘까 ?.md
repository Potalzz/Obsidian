
# [Graphics/Optimization] GPU 아키텍처와 선형대수의 필연성: 왜 우리는 행렬을 사용하는가?

그래픽스 프로그래밍, 특히 렌더링 파이프라인을 다루다 보면 직관적인 유클리드 기하학(각도, 거리)을 넘어 선형대수(행렬, 벡터)의 세계로 진입하게 된다. 단순히 수학적 표기의 우아함 때문이라고 생각하기 쉽지만, 사실 이 선택의 이면에는 **GPU 하드웨어의 설계 철학**과 **연산 효율성**에 대한 철저한 공학적 계산이 깔려있다.

본 포스팅에서는 컴퓨터 그래픽스에서 왜 삼각함수나 스칼라 연산 대신 행렬 연산을 지향해야 하는지, 그 이유를 GPU 아키텍처(ALU vs SFU)와 명령어 처리 방식(Instruction Pipeline)의 관점에서 구체적으로 분석해 본다.

---

## 1. 수학적 비용: 변환의 합성(Composition)과 연산 횟수의 최적화

그래픽스에서 물체를 화면에 그리기 위해서는 모델(Local) 공간에서 월드(World), 뷰(View), 클립(Clip) 공간으로 이어지는 수많은 좌표 변환 과정을 거친다.

### 삼각함수와 스칼라 연산의 한계 (O(N*M))

만약 행렬을 사용하지 않고, 이동(Translation), 회전(Rotation), 크기(Scale) 변환을 각각의 함수로 처리한다고 가정해 보자. 정점(Vertex) $v$에 대해 $M$개의 변환을 적용하려면, 모든 정점마다 삼각함수와 곱셈 연산을 $M$번씩 반복 수행해야 한다.

정점의 개수가 $N$개라면, 전체 연산 비용은 $O(N \times M)$으로 증가한다. 이는 렌더링 파이프라인에서 치명적인 병목을 유발한다.

### 행렬의 결합 법칙과 아핀 변환 (O(N))

선형대수의 가장 강력한 특징은 **행렬 곱셈의 결합 법칙((AB)C = A(BC))**이 성립한다는 점이다. 이동, 회전, 크기 변환을 나타내는 각각의 행렬 $T, R, S$를 미리 곱하여 하나의 **모델-뷰-프로젝션(MVP) 행렬**로 만들 수 있다.

$$M_{final} = P \times V \times M_{model}$$

이렇게 계산된 $M_{final}$ 행렬 하나만 GPU에 전달하면, 수만 개의 정점은 각각 단 한 번의 행렬-벡터 곱셈(Matrix-Vector Multiplication)만 수행하면 된다. 변환 단계가 아무리 복잡해도 정점 쉐이더(Vertex Shader)의 부하는 증가하지 않는다. 즉, 연산 비용이 $O(N)$으로 획기적으로 감소한다.

---

## 2. 하드웨어 아키텍처: ALU와 SFU의 비대칭성

수학적 최적화를 넘어, 실제 실리콘 레벨(Silicon Level)에서의 처리 효율을 살펴보자. GPU의 Streaming Multiprocessor(SM) 내부에는 연산의 종류에 따라 처리 유닛이 분리되어 있다.

- **ALU (Arithmetic Logic Unit):** 32-bit 부동소수점 덧셈(ADD), 곱셈(MUL), FMA 등을 처리.
    
- **SFU (Special Function Unit):** 초월함수(sin, cos, log, exp), 제곱근(sqrt, rsqrt), 나눗셈(rcp) 등을 처리.
    

### 희소한 자원, SFU (Special Function Unit)

현대 GPU 아키텍처(예: NVIDIA Ampere, Hopper 등)에서 ALU와 SFU의 비율은 대략 **16:1 또는 그 이상**으로 비대칭적이다. SFU는 칩 면적 대비 효율이 떨어지기 때문에 제한적으로 배치된다.

또한, SFU가 처리하는 삼각함수 연산은 하드웨어 내부적으로 테일러 급수 근사나 룩업 테이블(LUT) 보간 등을 수행하므로, 단일 사이클에 끝나는 ALU 연산보다 **Latency(지연 시간)**가 훨씬 길다. 쉐이더에서 `sin()`이나 `cos()`를 남발하면 ALU는 유휴 상태(Stall)가 되고 SFU 파이프라인에만 병목이 발생하여 전체적인 **Throughput(처리량)**이 급감한다.

### ALU 친화적인 행렬 연산

반면, 행렬 연산은 **순수한 덧셈과 곱셈(Linear Combination)**의 집합이다. 이는 GPU 내에 가장 많이 배치된 ALU 자원을 풀가동할 수 있는 최적의 형태다. 그래픽스 엔지니어가 쿼터니언(Quaternion)이나 행렬을 통해 회전을 구현하는 근본적인 이유는 비싼 SFU(삼각함수) 호출을 피하고 저렴한 ALU 연산으로 변환하기 위함이다.

---

## 3. 명령어 집합: FMA (Fused Multiply-Add)와 SIMD

GPU는 대량의 병렬 데이터 처리를 위해 **SIMD(Single Instruction, Multiple Data)** 구조를 가지며, 선형대수 연산에 특화된 명령어 세트를 하드웨어적으로 지원한다.

### FMA (Fused Multiply-Add)

행렬 곱셈과 내적(Dot Product)의 핵심 연산은 $A \times B + C$ 형태다. GPU는 이를 위해 **FMA** 명령어를 지원한다.

- **기존:** `MUL` (곱하기) 후 `ADD` (더하기) → 2번의 명령 사이클 필요. 또한 중간 과정에서 라운딩 오차 발생 가능.
    
- **FMA:** `MAD` 연산을 **단일 클럭 사이클**에 처리하며, 중간 라운딩 없이 최종 결과에서만 라운딩하여 정밀도가 더 높다.
    

즉, $4 \times 4$ 행렬 연산은 GPU 입장에서 가장 효율적인 FMA 명령어를 연속적으로 수행하는 '고속도로'와 같다.

---

## 4. 나눗셈의 비용과 최적화 (Reciprocal Multiplication)

GPU 연산에서 간과하기 쉬운 함정은 나눗셈($\div$)이다. 하드웨어적으로 나눗셈은 곱셈에 비해 매우 고비용 연산이다. 많은 아키텍처에서 나눗셈은 전용 ALU 회로가 없으며, SFU를 통해 역수(Reciprocal, $1/x$)를 구한 뒤 곱셈을 수행하는 방식으로 처리되거나, 반복적인 감산 알고리즘을 사용한다. 이는 곱셈 대비 약 **10~30배 이상의 사이클**을 소모할 수 있다.

따라서 셰이더 코드를 작성할 때 부동소수점 나눗셈은 피해야 한다.

High-level shader language

```
// [Bad] High Cost, SFU dependency
float3 result = targetVector / scalarValue;

// [Good] Low Cost, ALU optimized
float invScalar = 1.0 / scalarValue; // 역수는 한 번만 계산 (또는 CPU에서 미리 계산)
float3 result = targetVector * invScalar;
```

컴파일러가 상수 나눗셈(`x / 2.0`)은 최적화해주지만, 변수 나눗셈은 부동소수점 정밀도 규격(IEEE 754) 준수를 위해 자동으로 최적화하지 않는 경우가 많다. 따라서 개발자가 명시적으로 역수 곱셈 형태를 취하는 것이 바람직하다.

---

## 결론

그래픽스에서 선형대수를 사용하는 이유는 단순한 수학적 관례가 아니다. 그것은 **① 변환의 합성을 통한 연산 횟수의 절대적 감소(Algorithmic Optimization)**와 **② GPU 하드웨어(ALU/FMA) 특성을 극한으로 활용하기 위한 아키텍처 최적화(Architecture Optimization)**의 결과물이다.

고성능 렌더링을 목표로 한다면, '직관적인 코드'보다는 '하드웨어가 좋아하는 코드'를 작성해야 한다. 비싼 SFU(삼각함수, 나눗셈)를 아끼고, 저렴하고 빠른 ALU(행렬의 곱셈, 덧셈)를 활용하는 것이야말로 그래픽스 엔지니어링의 핵심 역량이다.