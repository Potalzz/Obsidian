## 구현한 기능
**프로젝트 CRUD**
- 정렬
- 복제



**SwiftData DB 구현**




**Volume관련 기능**
- 사이즈 조절시 다른 엔티티들 크기도 조정되도록
- volume영역 인디케이터 바로 위로 배치
- 회전 기능
- 벽면 충돌 감지
- floor이미지 적용



**Immersive**
- 낮밤 전환 기능 구현
	- hdri usda파일을 두 개 만들고 RCP내에서 조명을 통해 분위기 조절(entity material을 Phsycal based로 설정)
- volume - immersive 동기화
	- 하나의 rootEntity에 담고 scale 조절하여 띄워주기



**씬 상태 관리**
- AppState 중앙화로 상태 담고, Coordinator패턴으로 화면 이동 관리
- ScenePhase를 통해 씬 상태 확인하면서 예외 상황 처리
	- Immersive에서 window닫으면 다시 켤 수 없으므로 이전 화면으로 돌아가도록
	- volume닫으면 window이전 화면으로 돌아가도록
	- 디지털 크라운 버튼 클릭시 volume과 immersive에서 의도한대로 동작하도록



**Entity 관련**
- 이미지 양면 렌더링
	- 공식 API문서를 찾아보며 발견




**조이스틱 이슈 해결**
- 조이스틱 활성화 시에만 60fps Timer 실행
- 조이스틱 이동마다 realityView가 업데이트되어 성능 문제 발생 -> realityView update클로저 실행되지 않는 방향으로 진행




**공식 API문서 관련**
- 대부분의 개발을 공식 API문서에서 기능들을 찾아보며 작업했다. 아직 visionOS에 대한 부분은 AI도 빠삭하게 알 지 못하는 것 같다. 그로인해 visionOS의 view계층에 대해서도 직접 scenePhase값을 확인하고 테스트하며 알게 되었다.
- 종일 API문서만 쳐다보면서 작업하니 잘못 기재된 내용을 발견하고 feedBackAssistant에 제출도 하였다.

## 초안 양식
### 프로젝트 한 줄 소개 + 임팩트 훅
- 무엇을, 누구를 위해 만든 앱인지 한 문장으로.
- 숫자나 전/후 비교가 있으면 넣기 (예: 출시 후 3개월 내 활성 사용자 X명 등).

Apple Developer Academy @POSTECH에서 진행한 마지막 프로젝트인 Challenge 6가 마무리되었습니다.
지난 3개월간 visionOS에 열정이 가득한 팀원들과 함께 프로젝트를 진행할 수 있어 뜻깊은 경험이였습니다.


### 문제 정의(Problem)
- 해결하려던 비즈니스/사용자 문제.
- 왜 중요한지, 누가 영향을 받는지, 구체적인 상황 중심으로.

저희 팀은 영화 도메인에 속한 인원이 3명이 있었습니다.
각자 연출, 촬영, 후반작업으로 파트는 다르지만 이로 인해 영화 프로덕션의 전체적인 이해도를 높게 가져갈 수 있었습니다.

결과적으로 우리 팀은, 미술 감독의 아이디에이션 단계를 도와줌으로써 감독과 미술감독간의 커뮤니케이션 비용을 줄이고자 하였습니다.

기존에 미술감독이 공간을 디자인하기 위해 먼저 레퍼런스들을 수집하고, 무드보드를 만들어 감독에게 의도를 전달하는데, 무드보드에서는 구체적인 공간 구성을 확인하기 어려울 뿐더러 공간을 3D인데에 반해 2D 무드보드로 전체적인 느낌을 명확히 전달하기가 어려웠습니다. 스케치업으로 공간에 대한 구성을 3D로 제작하여 전달한다고 하더라도, 공간 배치에 대한 이해를 할 수 는 있지만 공간의 분위기에 대한 부분은 전달하기 어렵다는 문제가 있었습니다.

이로인해 무드보드를 공간적으로 쉽게 구현함으로써 미술 감독과 감독이 서로 원활히 소통할 수 있도록 소통 비용을 줄여주고자 하였습니다.

기존 미술감독이 공간을 디자인하기 위해 제작하는 무드보드를 Vision Pro에서 공간으로 쉽게 구현할 수 있게 도와줌으로써, 의도를 명확히 전달하고 감독과의 피드백이 즉각적으로 이루어지며 제작하려는 공간에 대한 이해도를 더욱 쉽게 맞추고 의도를 더욱 잘 전달할 수 있게 하고자 하였습니다.


### 역할과 환경(Context)
- 본인이 맡은 역할(기획/Frontend/Backend/풀스택 등)과 팀 구성.
- 기간, 사용하는 기술 스택, 협업 도구(Jira, Figma, Slack 등).

#### 구현한 기능 목록
**프로젝트 CRUD**
- 정렬
- 복제

**SwiftData DB 구현**

**Volume관련 기능**
- 사이즈 조절시 다른 엔티티들 크기도 조정되도록
- volume영역 인디케이터 바로 위로 배치
- 회전 기능
- 벽면 충돌 감지
- floor이미지 적용


**Immersive**
- 낮밤 전환 기능 구현
	- hdri usda파일을 두 개 만들고 RCP내에서 조명을 통해 분위기 조절(entity material을 Phsycal based로 설정)
- volume - immersive 동기화
	- 하나의 rootEntity에 담고 scale 조절하여 띄워주기


**씬 상태 관리**
- AppState 중앙화로 상태 담고, Coordinator패턴으로 화면 이동 관리
- ScenePhase를 통해 씬 상태 확인하면서 예외 상황 처리
	- Immersive에서 window닫으면 다시 켤 수 없으므로 이전 화면으로 돌아가도록
	- volume닫으면 window이전 화면으로 돌아가도록
	- 디지털 크라운 버튼 클릭시 volume과 immersive에서 의도한대로 동작하도록


**Entity 관련**
- 이미지 양면 렌더링
	- 공식 API문서를 찾아보며 발견


**조이스틱 이슈 해결**
- 조이스틱 활성화 시에만 60fps Timer 실행
- 조이스틱 이동마다 realityView가 업데이트되어 성능 문제 발생 -> realityView update클로저 실행되지 않는 방향으로 진행


**공식 API문서 관련**
- 대부분의 개발을 공식 API문서에서 기능들을 찾아보며 작업했다. 아직 visionOS에 대한 부분은 AI도 빠삭하게 알 지 못하는 것 같다. 그로인해 visionOS의 view계층에 대해서도 직접 scenePhase값을 확인하고 테스트하며 알게 되었다.
- 종일 API문서만 쳐다보면서 작업하니 잘못 기재된 내용을 발견하고 feedBackAssistant에 제출도 하였다.


### 접근 방식과 실행(Process)
- 아키텍처/기술 선택 이유, 주요 구현 포인트.
- 어떻게 우선순위를 정하고 개발·테스트·배포했는지.
- 스프린트나 애자일을 썼다면 간단히 언급.

개발은 1주일 단위의 스프린트로 진행하였고, 총 7주간의 스프린트 중 절반정도 지나왔을 때 팀원들 모두가 리팩토링의 필요성을 절실히 느끼게 되었습니다.

처음에 MVVM기반으로 개발을 진행하였는데, 초기에 ERD와 프로젝트 구조를 공들여 구성하였음에도 기능 구현을 최우선으로 두고 개발을 진행하다보니 특정 viewModel이 비대해지고, 각 기능간 결합도와 의존성이 지나치게 높아지는 문제가 발생하였습니다.
이로 인해 CleanArchitecture를 부분적으로 도입하여 UseCase와 Repository패턴을 통해서 결합도와 의존성을 낮추고자 하였습니다.


### 결과(Result)
- 정량 지표: 다운로드 수, 유지율, 성능 개선, 장애 감소 등.
- 정성 지표: 사용자 피드백, 내부 이해관계자 반응 등

sprint6부터는 다양한 사용자들에게 QA를 진행하며, 보완해나가는 식으로 개발을 진행했습니다. Vision Pro에 대해 익숙한 사용자와 처음 사용자가 느끼는 UX적 측면에서 차이가 발생했는데, 이러한 부분에서 타협을 맞추는 것이 또 하나의 도전이였습니다. 처음 앱을 실행시켰을 때 가이딩을 제공함으로써 이러한 문제를 해결하고자 노력하였습니다.


### 회고와 배운 점(Retrospective & Learnings)
- 잘 된 점: 다시 해도 유지하고 싶은 것.
- 아쉬웠던 점: 커뮤니케이션, 일정, 기술 부채 등.
- 다음에 다르게 할 것: 구체적인 개선 액션 2~3개.

showcase를 2주정도 앞두고, 실제 미술 감독에게 유용하지만 변화가 큰 피드백을 제공받았습니다. 공간을 직접 캡쳐하여 해당 공간을 바탕으로 에셋들을 배치함으로써 실제 세트장에서 소품 배치가 어떻게 될지 확인할 수 있으면 좋겠다라는 의견을 들었습니다. 하지만 개발 기간이 얼마 남지 않기도 하였고, 우리가 타겟하는 단계는 공간에 대한 컨셉을 시각화하고 제공하는 단계이기 때문에 실제 공간에 배치하는 단계와는 이전 단계라고 생각했습니다. 하지만 실제 타겟에게 제공받은 의견을 구현하지 못한 부분에 대해서는 아쉬움이 남습니다.

덕분에 초기에 보다 더 견고하게 쌓아올리기보다 빠르게 핵심 기능을 완성하고 실제 타겟과 밀접하게 소통하면서 서비스를 개선해나가는 것이 중요하다는 점을 배웠습니다.


### 마무리(Call to action)
- “비슷한 문제를 겪는 분들과 이야기 나누고 싶다” 등 네트워킹 유도 한 줄.

저희 팀의 앱Glayer에 관심있는 분들은 아래 웹사이트에 기능에 대한 구체적인 설명이 포함되어 있으니 방문해주시면 감사하겠습니다.


## 수정 버전v1(gemini)
**제목: 영화 미술 감독의 상상을 현실 공간으로, Vision Pro 앱 'Glayer' 개발기**

Apple Developer Academy @POSTECH에서의 지난 3개월은 단순한 앱 개발이 아닌, **'공간 컴퓨팅(Spatial Computing)'이라는 새로운 캔버스에 영화 제작의 미래를 그리는 시간**이었습니다.

영화 도메인 전문성을 가진 팀원들과 함께, 미술 감독님들의 페인 포인트를 해결하기 위해 달려온 여정을 공유합니다.

**🎬 Problem: 2D 무드보드의 한계를 넘어서** 영화 제작 과정에서 미술 감독은 공간의 톤 앤 매너를 전달하기 위해 수많은 레퍼런스를 모아 무드보드를 만듭니다. 하지만 2D 이미지와 스케치업만으로는 감독에게 **'공간의 분위기(Atmosphere)'**와 **'깊이감'**을 온전히 전달하기 어려웠고, 이는 잦은 수정과 커뮤니케이션 비용으로 이어졌습니다.

**💡 Solution: 공간 그 자체를 무드보드로 (Glayer)** 저희 팀은 **"미술 감독의 머릿속 의도를 3D 공간에 직관적으로 펼쳐놓을 수는 없을까?"**라는 질문에서 출발했습니다. Vision Pro를 통해 가상의 공간에 소품을 배치하고, 조명을 조절하며 감독과 실시간으로 '공간'을 보며 소통할 수 있는 솔루션, **Glayer**를 개발했습니다.


**🛠️ Tech & Challenge: 맨땅에 헤딩하며 쌓아 올린 기술** visionOS라는 낯선 환경에서, 문서조차 부족한 기능들을 구현하기 위해 수없이 공식 API 문서를 파고들었습니다.

- **몰입감 있는 환경 구축 (Immersive Space):** RealityKit과 HDRI를 활용해 Physical-based 조명을 구현하고, 낮/밤 전환 기능을 통해 공간의 분위기를 극대화했습니다.
    
- **직관적인 3D 인터렉션 (Volume & UX):** 윈도우와 볼륨(Volume) 간의 유기적인 동기화, 벽면 충돌 감지, 그리고 조이스틱 성능 최적화(60fps Timer & RealityView Update 최소화)를 통해 부드러운 사용자 경험을 만들었습니다.
    
- **프레임워크의 한계 극복:** Image 양면 렌더링 등 문서에 없는 기능들을 직접 실험하며 찾아냈고, 잘못된 API 내용은 Feedback Assistant에 제보하며 생태계 기여에도 노력했습니다.
    

**📈 Process & Growth: 사용자와 함께 만드는 프로덕트**

- **사용자 경험(UX)의 간극 조절:** Vision Pro 숙련자와 초심자 간의 조작 난이도 차이를 발견하고, 초기 가이딩(Onboarding)을 강화하여 진입 장벽을 낮췄습니다.
    
- **비즈니스 임팩트와 범위 설정:** 쇼케이스 2주 전, 실제 미술 감독님으로부터 "실제 촬영 현장(Passthrough) 위에 오버레이하고 싶다"는 피드백을 받았습니다. 기술적으로 욕심나는 기능이었지만, '초기 컨셉 시각화'라는 본질에 집중하기 위해 과감히 범위를 조절했습니다. 이 과정을 통해 **'기능 구현'보다 '핵심 가치 전달'이 우선**임을 배웠습니다.
    

**🚀 Next Step** Glayer는 이제 막 첫발을 뗐습니다. 공간 컴퓨팅이 가져올 영화 제작 환경의 변화가 기대되신다면, 아래 링크에서 더 자세한 내용을 확인해 주세요!

**[웹사이트/앱스토어 링크]**

#VisionPro #visionOS #SpatialComputing #RealityKit #SwiftUI #iOSDeveloper #AppleDeveloperAcademy #Startup #Glayer #영화제작 #공간컴퓨팅

---

### 📝 작성 팁 및 보완 가이드 (게시 전 확인!)

1. **시각 자료 필수:**
    
    - **영상/GIF:** 조이스틱으로 물체를 이동시키는 모습, 낮/밤이 바뀌며 조명이 변하는 모습 등 'Glayer'의 핵심 기능이 잘 보이는 15~30초짜리 영상을 반드시 첨부하세요.
        
    - **Architecture 다이어그램:** MVVM에서 Clean Architecture로 리팩토링한 구조도가 있다면 이미지로 첨부하여 전문성을 보여주세요.
        
2. **구체적인 성과 보완 (가능하다면):**
    
    - `[결과]` 섹션에 "총 O번의 유저 테스트 진행", "베타 테스터 O명 모집" 등의 숫자가 들어가면 신뢰도가 올라갑니다.
        
3. **태그(@):**
    
    - 함께 고생한 팀원들, 멘토, Apple Developer Academy 계정을 태그하여 도달률을 높이세요.
        
4. **섹션별 개선 포인트:**
    
    - **Tech:** "조이스틱 이슈 해결" -> **"성능 최적화와 사용자 인터렉션 개선"**과 같이 좀 더 전문적인 용어로 다듬었습니다.
        
    - **Process:** 리팩토링 경험을 단순한 수정이 아닌, **"확장성을 고려한 아키텍처 도입"** 이라는 성장 서사로 풀었습니다.
        
    - **Retrospective:** 피드백을 반영하지 못한 것을 아쉬움으로 끝내지 않고, **"PM으로서의 의사결정(Scope Management)"** 능력으로 포장했습니다.



## Medium 블로그 업로드용
**임팩트 있는 한 줄 소개 ->문제 정의 -> 접근 방식과 실행-> 실행 단계에서 마주한 문제와 해결 방법 -> 배운 점 -> 마무리**

제목: Apple Developer Academy 마지막 챌린지 회고 - visionOS 앱 개발

**(임팩트 있는 한 줄 소개)**
"감독님, 이 공간은 조금 더 스산한 분위기와 다정함이 공존하는 느낌입니다."
[2D 레퍼런스 이미지]
영화 기획 단계에서 말과 2D 이미지만으로 머릿속의 이미지를 100% 공유하기란 쉽지 않다.

Apple Developer Academy @POSTECH에서 마지막 프로젝트를 진행한 지난 3개월,
영화 미술감독과 감독 사이에서 반복적으로 발생하던 소통의 간극을 해결하고자 했던 경험을 공유하고자 한다.

**(문제 정의)**
기존 무드보드 제작은 언제나 2D 이미지 위에서 이루어졌고, 스케치업을 통해 3D로 제작하더라도 공간의 분위기를 전달하기란 쉽지 않다.
[3D 스케치업 이미지]
그 결과, 커뮤니케이션에서 오해가 반복되고 수정이 쌓여가게 된다.

Glayer는 이 과정을 Vision Pro를 통해 무드보드를 공간적으로 구성하고,
감독과 미술감독 모두가 같은 공간을 바라보며 커뮤니케이션 비용을 줄일 수 있도록 돕는 것을 목표로 잡았다.


**(접근 방식과 실행)**
간단하게 제작해 의도를 전달해야 하는 무드보드 특성을 고려하여, 의도를 명확히 담는 것과 간편한 제작 두 경계 사이에서 많은 고민을 했다.

앱의 기능에 대한 세부적인 설명은 아래 Glayer 웹사이트에 자세하게 설명이 포함되어 있다.
[Glayer Website](https://glayer.framer.website/_)


이 중에서 나는 프로젝트와 Volume에 대한 전반적인 기능 및 DB와 전체적인 앱 상태 관리를 도맡아 진행하였다.

특히 앱의 특성상 volume과 immersive간 상태가 동기화되어야 하기 때문에, 생성되는 모든 Entity를 하나의 rootEntity에 넣어서 관리했다. 때문에 volume에서 resize할 때 크기를 일괄적으로 조절하기가 수월했다.

[volume Resize기능 GIF]

Volume Resize 기능을 구현하는 데에는 아래 자료를 많이 참고하였다.
[stepintovision 링크]


**DataBase는 SwiftData로 구현**

**Volume관련 기능**
- 사이즈 조절시 다른 엔티티들 크기도 조정되도록
- volume영역 인디케이터 바로 위로 배치
- 회전 기능
- 벽면 충돌 감지
- floor이미지 적용

**Immersive**
- 낮밤 전환 기능 구현
	- hdri usda파일을 두 개 만들고 RCP내에서 조명을 통해 분위기 조절(entity material을 Phsycal based로 설정)
- volume - immersive 동기화
	- 하나의 rootEntity에 담고 scale 조절하여 띄워주기

**조이스틱 이슈 해결**
- 조이스틱 활성화 시에만 60fps Timer 실행
- 조이스틱 이동마다 realityView가 업데이트되어 성능 문제 발생 -> realityView update클로저 실행되지 않는 방향으로 진행




**앱의 전체적인 상태관리**
앱에 depth가 깊은 편은 아니였지만, 상황별로 메인 window를 키고 끄거나 volume과 immersive간 이동을 해야 하는 분기들이 있었기에 중앙화 관리가 필요했다.

이로인해 기존에 환경 변수를 주입해 각 view에서 openwindow/dismisswindow로 제어하는 방식을 철회하고, AppState를 중앙화하여 Single of True Source로 관리하고 Coordinator 패턴을 도입해 MainWindowView에서 관리했다.

특히 visionOS의 view계층에 대한 이해가 부족했기에 의도한대로 구현하기 위해 초반에 많은 애를 먹었다.
visionOS에서의 view계층에 대한 자세한 내용은 아래 글을 참고하길 바란다.
[visionOS에서 view계층](링크)
- view복원하지 않게 하는 modifier
- 직접 ActivateSceneID 확인해가며 테스트한 스크린샷과 내용
- onDisAppear가 동작하지 않아 따로 extension을 만들게 된 이유



**마무리 멘트**









## 수정 버전v2_전체적인스토리(gemini)

**[제목: 2D 무드보드를 넘어, 감독의 상상을 공간으로 옮기다]**

지난 3개월, Apple Developer Academy @POSTECH에서 진행한 마지막 프로젝트가 드디어 막을 내렸습니다. 영화 도메인 백그라운드를 가진 팀원들과 함께 **Vision Pro 앱 'Glayer'**를 개발하며, 공간 컴퓨팅이라는 새로운 캔버스에 도전했습니다.

**🎥 왜 이 앱을 만들었나?**
영화 제작 과정에서 미술 감독은 공간의 느낌을 전달하기 위해 무드보드를 만듭니다. 하지만 2D 이미지와 스케치업만으로는 감독에게 '공간감'과 '분위기'를 온전히 전달하기 어려웠고, 이는 늘 커뮤니케이션 비용의 증가로 이어졌습니다. 
Glayer는 **Vision Pro의 현실과 같은 공간을 활용해 눈앞에 실체화**함으로써 이 문제를 해결하고자 했습니다.

**낯선 기술, 집요한 탐구**
visionOS 생태계는 아직 초기 단계라 참고할 자료가 상대적으로 부족했습니다.
대부분의 개발 기간동안 직접 API공식 문서를 보고 공부하고, 잘못된 API 내용을 찾아내 Feedback Assistant에 제보하기도 하며 개발을 이어갔습니다.

특히, 사용자가 가상 공간에 몰입하도록 낮/밤 조명을 전환하는 **Immersive Space** 구현부터, 직관적인 조작을 위한 **Volume-Window 동기화**와 **조이스틱 성능 최적화**까지 기술적 난관이 많았습니다. 개발 중간에는 코드가 복잡해지는 것을 막기 위해 **Clean Architecture**를 도입하는 대공사를 감행하기도 했습니다. 이 과정은 단순한 코딩을 넘어, 견고한 제품을 만들기 위한 치열한 고민의 연속이었습니다.

**🌱 아쉬움이 남긴 교훈** 가장 기억에 남는 순간은 쇼케이스 직전입니다. 실제 미술 감독님으로부터 "실사 배경 위에 오버레이하고 싶다"는 피드백을 받았을 때였습니다. 기술적으로 도전해보고 싶었지만, 저희는 **'초기 아이디에이션 단계'**라는 타겟에 집중하기 위해 기능을 덜어내는 결정을 내렸습니다. 모든 피드백을 수용하기보다, 프로덕트의 핵심 가치를 지키는 것이 더 중요하다는 것을 깨달은 소중한 경험이었습니다.

이제 Glayer는 세상에 첫발을 내디뎠습니다. 공간 컴퓨팅이 가져올 영화 제작 환경의 변화가 궁금하신 분들은 아래 링크를 방문해 주세요.



## 최종 LinkedIn 버전 양식
기술적인 부분보다 프로젝트에 대한 전반적인 경험을 공유.
기술적인 내용은 medium에 업로드하여 링크 남기기

지난 3개월 동안 Apple Developer Academy @POSTECH에서 visionOS 기반 앱 **Glayer**를 개발했습니다.

**Glayer**는 영화 미술감독이 공간의 분위기와 콘셉트를 감독에게 명확하게 전달할 수 있도록, 기존의 2D 무드보드를 Vision Pro를 통해 **직관적인 3D 공간으로 시각화**해주는 도구입니다.

영화 산업에 관한 경험이 있는 팀원들과 함께 제작하면서, 미술감독과 감독 사이에서 반복적으로 발생하던 커뮤니케이션 문제를 현실적인 시각에서 바라볼 수 있었습니다.
기존 미술감독과 감독이 소통의 도구로 사용하는 무드보드는 2D 이미지 기반이라 공간의 깊이·빛·재질감 같은 중요한 요소를 전달하기 어려웠고, 그로 인해 수차례의 오해와 수정이 반복되는 문제가 있었습니다.
Glayer는 이 과정을 Vision Pro의 공간 컴퓨팅을 통해 무드보드를 공간적으로 구성하고, 감독과 미술감독 모두가 같은 공간을 바라보며 커뮤니케이션 비용을 줄일 수 있도록 돕는 것을 목표로 했습니다.

프로젝트를 진행하면서 영화 업계에 종사한 팀원들과의 경험과, 현업에 종사중인 감독과 인터뷰를 진행하며 기능을 하나씩 정제해 나갔으며, visionOS의 기술을 영화 도메인에 적용해보는 과정 자체가 매우 뜻깊은 경험이었습니다. 특히 다양한 사용자 테스트를 거치면서 익숙한 사용자와 처음 사용하는 사용자 간의 경험 차이를 확인하고, QA를 진행하며 가이드 제공과 UX 개선을 반복했던 점이 큰 배움으로 남았습니다.

전반적으로 아카데미에서 경험한 마지막 프로젝트는 **새로운 플랫폼을 빠르게 실험하고**, **도메인 문제를 기술로 풀어내는 경험을 쌓으며**, **팀의 강점을 활용해 근본적인 문제를 정의하고 해결 방향을 구체화**하는 과정이었습니다.

Glayer 프로젝트에 대한 구체적인 내용은 따로 정리하여 블로그에 기록해 두었습니다.
관심 있으신 분들은 아래 링크에서 확인해주시면 감사하겠습니다.
  
**Medium 블로그 링크**
링크

함께 고생한 팀원들
고승아(Green), 이가원(Monica), 정민지(My), 최윤(Yoon), 차봉준(Tether)
그리고 프로젝트 전반에서 많은 도움을 주신 Junmin Lee(Gommin), Minji Lee(Judy)에게 감사드립니다.

앞으로도 visionOS를 통해 실제 문제를 해결하고, 새로운 페러다임을 제시하는 프로젝트를 이어가고자 합니다. 관련 분야에 관심 있으신 분들은 언제든지 편하게 이야기 나눌 수 있으면 좋겠습니다.

Glayer App Store 링크
링크

Glayer 홈페이지
링크



## visionOS view계층
visionOS에서 x버튼으로 윈도우 닫는 트리거 감지.
ai에게 물어봐도 해당 방법을 감지하는 방법은 없다고 함.
하지만, UIScene에서 명확하게 background로 전환되는 변경이 있기 때문에 해당 부분을 감지해서 원하는 작업을 실행시킬 수 있음.

`onDisappear`가 실행되지 않는 이유는, view가 사라지는게 아니라 background로 전환되기 때문. background상태에서 종료되는 시점은 내부 로직에 숨겨져있기 때문에 알 수 없음.(메모리 할당 관련하여 무거워지면 crash로 추정)
*(onDisappear과 onAppear가 정확히 어떤 상황에서 어떻게 동작하는지 자세한 설명)*

**제공하는 정보**
- visionOS에서 x 버튼은 mac에서 최소화 버튼과 동일하다
	- 세부적으로 어떻게 동작하는지
- visionOS Window의 view계층 등록과 삭제에 대한 상태를 나열
- 사용할 수 있는 view Extension코드 제공

