**단순 제자리 360 VR을 타겟할지 3D 공간 워킹(6DoF)을 타겟할지**

사용자가 본인 iPhone으로 앱의 가이드에 맞춰 집을 scan해서 업로드하면, VR기기를 통해서 해당 공간을 직접 투어할 수 있다.

iOS + visionOS 통합
iOS로도 해당 공간을 웹 vr형식으로 확인할 수 있고 visionPro로 실제 걸어다니면서 볼 수 있는 구조.

**직접 모델을 만들어야 할까 ?**
사용자가 촬영하면 gaussian splatting으로 공간을 직접 구성해주는 모델 만들기 .?

### iOS + Gaussian Splatting 기술 결합 가이드
****Gaussian Splatting(가우시안 스플래팅)** 기술은 아이폰으로 찍은 2D 영상/사진을 AI가 학습하여, 공간을 수만~수백만 개의 **'3D 입자(Gaussian Splats)'** 구름으로 표현하는 방식입니다.

팀 내 엔지니어가 있다면, **고가의 장비(Matterport) 없이** 아이폰 하나로 고품질의 실사 3D 공간을 만들어낼 수 있습니다. 특히 부동산에서 중요한 **'질감(대리석 바닥, 가죽 소파)'**과 **'반사(유리창, 거울)'** 표현에 있어 기존 3D 메쉬 방식보다 월등합니다.

구체적인 **[촬영 -> 처리 -> Vision Pro 포팅]** 파이프라인을 설명해 드립니다.

---

#### 1단계: 촬영 (Data Capture) - 아이폰 활용

이 단계가 퀄리티의 90%를 결정합니다. 일반 동영상 촬영과는 다르게 찍어야 합니다.

- **추천 앱:** **Luma AI** (현재 업계 표준), **Scaniverse** (온디바이스 처리 가능), **Polycam**
    
- **촬영 기법 (엔지니어/촬영자 필독):**
    
    1. **비디오 모드:** 사진을 한 장씩 찍는 것보다, 4K 60fps 비디오로 천천히 걸으며 찍는 것이 데이터 확보에 유리합니다.
        
    2. **움직임:** **게걸음(Crab walk)**이 필수입니다. 카메라를 정면을 보게 한 상태에서 몸을 좌우로 이동하며 피사체의 입체감을 확보해야 합니다.
        
    3. **루프(Loop) & 레벨(Level):**
        
        - 방의 가장자리를 따라 크게 한 바퀴 돕니다 (눈높이).
            
        - 가능하다면 무릎 높이에서 한 바퀴, 손을 뻗어 높은 시점에서 한 바퀴 더 돕니다. (다각도 확보)
            
    4. **주의사항:** 절대 제자리에서 몸만 돌리는(파노라마 식) 촬영을 하면 안 됩니다. **카메라의 위치(Position)**가 계속 바뀌어야 공간감이 계산됩니다.
        

#### 2단계: 학습 및 처리 (Training & Processing)

촬영된 영상 데이터를 3D 가우시안 데이터로 변환하는 과정입니다. 두 가지 경로가 있습니다.

##### A. 앱/클라우드 활용 (빠른 프로토타이핑)

- **방법:** Luma AI 앱에 영상을 업로드합니다.
    
- **과정:** 서버에서 약 30분~1시간 정도 연산을 수행합니다.
    
- **결과물:** 앱 내에서 즉시 확인 가능하며, **`.ply` (Standard Gaussian Splatting)** 또는 **`.splat`** 파일로 다운로드할 수 있습니다.
    
- **비용:** 기본 무료, 고화질/대량 처리는 유료 플랜.
    

##### B. 로컬 PC 활용 (비용 절감 & 보안 & 고퀄리티)

팀 내 엔지니어가 수행할 수 있는 전문적인 방법입니다.

1. **데이터 추출:** 아이폰 영상을 PC로 옮기고 `ffmpeg` 등을 이용해 프레임(이미지) 단위로 쪼갭니다.
    
2. **위치 추정 (COLMAP):** `COLMAP`이라는 오픈소스 툴을 돌려 사진마다 카메라가 어디에 있었는지(Pose Estimation) 계산합니다.
    
3. **학습 (Training):** 공식 Gaussian Splatting 소스코드(Inria)나 `Postshot`, `Nerfstudio` 같은 툴을 사용하여 GPU(NVIDIA 권장)로 공간을 학습시킵니다.
    
4. **장점:** 클라우드 비용 0원, 데이터 외부 유출 없음, 입자 수(Density) 직접 조절 가능.
    

#### 3단계: Vision Pro 포팅 (Integration)

생성된 `.ply` 파일은 원본 그대로는 용량이 크고(수백 MB~GB), Vision Pro에서 바로 열리지 않습니다.

##### Unity + PolySpatial (추천)

가장 안정적인 방법입니다.

1. **플러그인 설치:** Unity 프로젝트에 **Luma AI SDK** 또는 **Gaussian Splatting 렌더러(오픈소스)**를 설치합니다.
    
2. **에셋 임포트:** 추출한 `.ply` 파일을 Unity로 가져옵니다.
    
3. **쉐이더 처리:** 일반 3D 모델과 렌더링 방식이 다르므로 전용 쉐이더가 필요합니다. (SDK가 처리해 줌)
    
4. **최적화:** 파일 용량을 줄이기 위해 `Compressed Splats` 포맷으로 변환하거나, 불필요한 배경(천장 위, 창문 밖 노이즈)을 잘라냅니다(Cropping).
    
5. **빌드:** Vision Pro용으로 빌드하여 배포합니다.
    

##### Native (Swift/Metal)

앱 용량을 극단적으로 줄이고 싶을 때 사용합니다.

- **MetalSplatter:** 오픈소스 라이브러리로, RealityKit이나 Metal 뷰어에서 직접 `.ply` 파일을 렌더링할 수 있게 해줍니다. 엔지니어의 Swift/Metal 숙련도가 필요합니다.**

|**비교 항목**|**Matterport (기존 방식)**|**Gaussian Splatting (아이폰)**|
|---|---|---|
|**유리/거울 표현**|불가능하거나 깨짐 (구멍 남)|**실제처럼 반사됨 (매우 우수)**|
|**조명/분위기**|인위적인 3D 그래픽 느낌|**사진/영상 그대로의 실사 느낌**|
|**공간 정확도**|높음 (치수 측정 가능)|낮음 (치수 측정용으론 부적합)|
|**이동 자유도**|6DoF (자유 이동)|6DoF (자유 이동)|
|**파일 용량**|작음 (최적화 쉬움)|**매우 큼 (VRAM 관리 필요)**|

### ---
